{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c8d805c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged datasets\n",
    "als_data = pd.read_csv('/Users/opethompson/Desktop/ALS PROCESSED/Diagnostics/ALS Diagnosis (ALS Natural History).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8e68b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for dropping columns (50% missing values)\n",
    "threshold = 0.5\n",
    "columns_to_drop = als_data.columns[als_data.isnull().mean() > threshold]\n",
    "als_data.drop(columns=columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17dcd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing data: For numerical columns, we use the median; for categorical columns, we use the mode\n",
    "for col in als_data.columns:\n",
    "    if als_data[col].dtype == 'object':  # Categorical data\n",
    "        als_data[col].fillna(als_data[col].mode()[0], inplace=True)\n",
    "    else:  # Numerical data\n",
    "        als_data[col].fillna(als_data[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a83f8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Rows with Missing Values\n",
    "als_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "399744f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace every occurrence of 99 with 0\n",
    "als_data = als_data.replace(99, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efc78ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace every occurrence of 90 with 0\n",
    "als_data = als_data.replace(90, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "222127a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new file\n",
    "als_data.to_csv('preprocessedALShx_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae17eae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6212121212121212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.70      0.64        30\n",
      "           2       0.50      0.47      0.48        47\n",
      "           3       0.57      0.38      0.45        45\n",
      "           4       0.58      0.68      0.63       100\n",
      "           5       0.75      0.71      0.73       108\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.60      0.59      0.59       330\n",
      "weighted avg       0.62      0.62      0.62       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training and evaluation\n",
    "#Load data set\n",
    "df= pd.read_csv('/Users/opethompson/Desktop/ALS PROCESSED/preprocessedALShx_data.csv')\n",
    "\n",
    "#Building and Evaluating the Model for ALS Diagnosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Split the data\n",
    "X = df.drop('elescrlr', axis=1)\n",
    "y = df['elescrlr']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "modeldx = RandomForestClassifier()\n",
    "modeldx.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = modeldx.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Calculate ROC-AUC for binary classification tasks\n",
    "# We must check if y is binary before applying roc_auc_score\n",
    "if len(y.unique()) == 2:\n",
    "    probs = modeldx.predict_proba(X_test)[:, 1]  # get the probabilities of the positive class\n",
    "    roc_auc = roc_auc_score(y_test, probs)\n",
    "    print(\"ROC-AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ea0a287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('internal_subject_id', 0.1943334199959146),\n",
       " ('blbcumn', 0.07199887079510064),\n",
       " ('blbclmn', 0.05702231890619021),\n",
       " ('trnkclmn', 0.05362854871856702),\n",
       " ('trnkelmn', 0.04817391724854775),\n",
       " ('rleelmn', 0.048002079849190395),\n",
       " ('rueelmn', 0.04762260819523785),\n",
       " ('trnkcumn', 0.04750520348741263),\n",
       " ('blbelmn', 0.04701654473291307),\n",
       " ('lleelmn', 0.0468976284140643)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance Analysis\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Extracting feature importances\n",
    "importance_diagnosis = modeldx.feature_importances_\n",
    "\n",
    "# Function to summarize feature importances\n",
    "def summarize_feature_importances(importances, feature_names, top_n=10):\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    top_features = [(feature_names[i], importances[i]) for i in indices[:top_n]]\n",
    "    return top_features\n",
    "\n",
    "# Top features for ALS Diagnosis\n",
    "top_features_diagnosis = summarize_feature_importances(importance_diagnosis, df.columns)\n",
    "\n",
    "top_features_diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c05d2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend treatment based on ALS diagnosis\n",
    "def recommend_treatment(diagnosis):\n",
    "    \"\"\"\n",
    "    Recommends treatment based on ALS diagnosis.\n",
    "\n",
    "    :param diagnosis: The diagnosis result (1, 2, 3, 4, 5)\n",
    "    :return: Recommended treatment\n",
    "    \"\"\"\n",
    "    if diagnosis == 5:\n",
    "        return \"Standard ALS treatment protocol\"\n",
    "    elif diagnosis == 4:\n",
    "        return \"Probable ALS treatment protocol\"\n",
    "    elif diagnosis == 2 or diagnosis == 3:\n",
    "        return \"Conservative observation and symptomatic treatment\"\n",
    "    else:\n",
    "        return \"Further diagnostic evaluation required\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63703c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
