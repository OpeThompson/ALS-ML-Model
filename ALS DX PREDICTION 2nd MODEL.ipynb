{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c8d805c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged datasets\n",
    "als_data = pd.read_csv('/Users/opethompson/Desktop/ALS PROCESSED/Diagnostics/ALS Diagnosis (ALS Natural History).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8e68b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for dropping columns (50% missing values)\n",
    "threshold = 0.5\n",
    "columns_to_drop = als_data.columns[als_data.isnull().mean() > threshold]\n",
    "als_data.drop(columns=columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17dcd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing data: For numerical columns, we use the median; for categorical columns, we use the mode\n",
    "for col in als_data.columns:\n",
    "    if als_data[col].dtype == 'object':  # Categorical data\n",
    "        als_data[col].fillna(als_data[col].mode()[0], inplace=True)\n",
    "    else:  # Numerical data\n",
    "        als_data[col].fillna(als_data[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a83f8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Rows with Missing Values\n",
    "als_data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f83fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace every occurrence of 99 with 0\n",
    "als_data = als_data.replace(99, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d27a4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace every occurrence of 90 with 0\n",
    "als_data = als_data.replace(90, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "222127a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new file\n",
    "als_data.to_csv('preprocessedALShx_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af1400d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.997325813701823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      9385\n",
      "           2       1.00      1.00      1.00     13158\n",
      "           3       0.99      0.99      0.99     14596\n",
      "           4       0.99      1.00      0.99     24747\n",
      "           5       1.00      1.00      1.00     34218\n",
      "\n",
      "    accuracy                           1.00     96104\n",
      "   macro avg       1.00      1.00      1.00     96104\n",
      "weighted avg       1.00      1.00      1.00     96104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Building and Evaluating the Model for ALS diagnosis\n",
    "#Load data set\n",
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv('/Users/opethompson/Desktop/preprocessedALSclean_data.csv')\n",
    "\n",
    "#Building and Evaluating the Model for ALS Diagnosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X = df.drop('elescrlr', axis=1)\n",
    "y = df['elescrlr']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "modeldx = RandomForestClassifier()\n",
    "modeldx.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = modeldx.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "# Calculate precision, recall, and F1-score\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Calculate ROC-AUC for binary classification tasks\n",
    "# We must check if y is binary before applying roc_auc_score\n",
    "if len(y.unique()) == 2:\n",
    "    probs = modeldx.predict_proba(X_test)[:, 1]  # get the probabilities of the positive class\n",
    "    roc_auc = roc_auc_score(y_test, probs)\n",
    "    print(\"ROC-AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad6fa2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9795013735120286\n"
     ]
    }
   ],
   "source": [
    "#Building and Evaluating the Model for ALS Phenotype\n",
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv('/Users/opethompson/Desktop/preprocessedALSclean_data.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X = df.drop('cdalsphn', axis=1)\n",
    "y = df['cdalsphn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "modelph = RandomForestClassifier()\n",
    "modelph.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = modelph.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a20ccf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('internal_subject_id', 0.1943334199959146),\n",
       " ('blbcumn', 0.07199887079510064),\n",
       " ('blbclmn', 0.05702231890619021),\n",
       " ('trnkclmn', 0.05362854871856702),\n",
       " ('trnkelmn', 0.04817391724854775),\n",
       " ('rleelmn', 0.048002079849190395),\n",
       " ('rueelmn', 0.04762260819523785),\n",
       " ('trnkcumn', 0.04750520348741263),\n",
       " ('blbelmn', 0.04701654473291307),\n",
       " ('lleelmn', 0.0468976284140643)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance Analysis\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Extracting feature importances\n",
    "importance_diagnosis = modeldx.feature_importances_\n",
    "\n",
    "# Function to summarize feature importances\n",
    "def summarize_feature_importances(importances, feature_names, top_n=10):\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    top_features = [(feature_names[i], importances[i]) for i in indices[:top_n]]\n",
    "    return top_features\n",
    "\n",
    "# Top features for ALS Diagnosis\n",
    "top_features_diagnosis = summarize_feature_importances(importance_diagnosis, df.columns)\n",
    "\n",
    "top_features_diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd1a0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend treatment based on ALS diagnosis\n",
    "def recommend_treatment:\n",
    "    \"\"\"\n",
    "    Recommends treatment based on ALS diagnosis.\n",
    "\n",
    "    :param diagnosis: The diagnosis result (1, 2, 3, 4, 5)\n",
    "    :return: Recommended treatment\n",
    "    \"\"\"\n",
    "    if diagnosis == 5:\n",
    "        return \"Standard ALS treatment protocol\"\n",
    "    elif diagnosis == 4:\n",
    "        return \"Probable ALS treatment protocol\"\n",
    "    elif diagnosis == 2 or diagnosis == 3:\n",
    "        return \"Conservative observation and symptomatic treatment\"\n",
    "    else:\n",
    "        return \"Further diagnostic evaluation required\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0853b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend treatment based on ALS diagnosis\n",
    "\n",
    "if phenotype == 'UMN-predominant':\n",
    "    treatment_plan += ' and UMN-focused therapy'\n",
    "elif phenotype == 'LMN-predominant':\n",
    "    treatment_plan += ' and LMN-focused therapy'\n",
    "else:\n",
    "    treatment_plan += ' and Bulbar symptoms management'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the state space\n",
    "states = {\n",
    "    'Start': {'ALS': True, 'Treatment': None},\n",
    "    'Treatment1': {'ALS': True, 'Treatment': 'conservative'},\n",
    "    'Treatment2': {'ALS': True, 'Treatment': 'physical therapy'},\n",
    "    'Treatment3': {'ALS': True, 'Treatment': 'riluzole'},\n",
    "    'Goal': {'ALS': False, 'Treatment': 'Recovered'}\n",
    "}\n",
    "\n",
    "# Define transitions between states (example)\n",
    "transitions = {\n",
    "    'Start': [('Treatment1', 1), ('Treatment2', 2)],\n",
    "    'Treatment1': [('Treatment3', 3), ('Goal', 4)],\n",
    "    'Treatment2': [('Treatment3', 2), ('Goal', 5)],\n",
    "    'Treatment3': [('Goal', 1)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement the Greedy Best-First Search Algorithm\n",
    "\n",
    "def greedy_best_first_search(start, goal, states, transitions):\n",
    "    # Initialize the open list with the start state\n",
    "    open_list = [(start, 0)]  # (state, cost)\n",
    "    closed_list = set()\n",
    "\n",
    "    while open_list:\n",
    "        # Choose the state with the lowest cost\n",
    "        state, cost = min(open_list, key=lambda x: x[1])\n",
    "        open_list.remove((state, cost))\n",
    "\n",
    "        # Check if the goal is reached\n",
    "        if state == goal:\n",
    "            return state, cost\n",
    "\n",
    "        # Add state to closed list\n",
    "        closed_list.add(state)\n",
    "\n",
    "        # Add neighbors to the open list\n",
    "        for neighbor, step_cost in transitions.get(state, []):\n",
    "            if neighbor not in closed_list:\n",
    "                total_cost = cost + step_cost\n",
    "                open_list.append((neighbor, total_cost))\n",
    "\n",
    "    return None, float('inf')  # Goal not reached\n",
    "\n",
    "# Example usage\n",
    "start_state = 'Start'\n",
    "goal_state = 'Goal'\n",
    "optimal_state, total_cost = greedy_best_first_search(start_state, goal_state, states, transitions)\n",
    "print(f\"Optimal State: {optimal_state}, Total Cost: {total_cost}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Python Code for Back-End Server\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Loading the trained models (saved as .pkl files)\n",
    "diagnosis_model = joblib.load('diagnosis_model.pkl')\n",
    "phenotype_model = joblib.load('phenotype_model.pkl')\n",
    "\n",
    "@app.route('/predict_diagnosis', methods=['POST'])\n",
    "def predict_diagnosis():\n",
    "    data = request.json  # Get data from POST request\n",
    "    # Preprocess the data as per the model requirements\n",
    "    # ...\n",
    "    # Make a prediction\n",
    "    prediction = diagnosis_model.predict(data)\n",
    "    return jsonify({'diagnosis_prediction': prediction.tolist()})\n",
    "\n",
    "@app.route('/predict_phenotype', methods=['POST'])\n",
    "def predict_phenotype():\n",
    "    data = request.json  # Get data from POST request\n",
    "    # Preprocess the data as per the model requirements\n",
    "    # ...\n",
    "    # Make a prediction\n",
    "    prediction = phenotype_model.predict(data)\n",
    "    return jsonify({'phenotype_prediction': prediction.tolist()})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704edb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Model with user inputs\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the trained models\n",
    "diagnosis_model = joblib.load('diagnosis_model.pkl')\n",
    "phenotype_model = joblib.load('phenotype_model.pkl')\n",
    "\n",
    "def get_user_input():\n",
    "    # User inputs\n",
    "    age = int(input(\"Enter age: \"))\n",
    "    sex = input(\"Enter sex (Male/Female): \")\n",
    "    # ALSFRS scores are a series of numbers\n",
    "    alsfrs_scores = [int(x) for x in input(\"Enter ALSFRS scores separated by space: \").split()]\n",
    "    roads_score = int(input(\"Enter RoADS score: \"))\n",
    "\n",
    "    # Convert inputs to features \n",
    "    features = [age] + [sex] + alsfrs_scores + [roads_score]\n",
    "    # Feature engineering and scaling need to be done here as per the model's training\n",
    "    # ...\n",
    "    return np.array([features])\n",
    "\n",
    "def predict_als(features):\n",
    "    diagnosis_prediction = diagnosis_model.predict(features)\n",
    "    phenotype_prediction = phenotype_model.predict(features)\n",
    "    return diagnosis_prediction, phenotype_prediction\n",
    "\n",
    "# Get user input\n",
    "user_features = get_user_input()\n",
    "\n",
    "# Predict ALS diagnosis and phenotype\n",
    "diagnosis, phenotype = predict_als(user_features)\n",
    "\n",
    "print(f\"Predicted ALS Diagnosis: {diagnosis[0]}\")\n",
    "print(f\"Predicted ALS Phenotype: {phenotype[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
